{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f133c74-b135-43f1-8d48-9a586c1f085c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from typing import Any\n",
    "\n",
    "from torchvision.models import MobileNet_V3_Small_Weights as mweights\n",
    "from torchvision.models import mobilenet_v3_small as mnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f54980bb-b615-49c7-b113-a92d588e87cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BasicConv2d(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int, **kwargs: Any) -> None:\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, bias=False, **kwargs)\n",
    "        self.bn = nn.BatchNorm2d(out_channels, eps=0.001)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        return F.relu(x, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dab894e7-945f-4545-b7c6-14ae92eb3e97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DecoderBlock(nn.Module):\n",
    "    def __init__( self, in_channels: int, out_channels: int ) -> None:\n",
    "        super().__init__()\n",
    "        self.deconv = nn.ConvTranspose2d\n",
    "        \n",
    "        self.branch1_1 = self.deconv(in_channels=in_channels, out_channels=out_channels, kernel_size=2, stride=2)\n",
    "        \n",
    "        self.branch2_1 = self.deconv(in_channels=in_channels, out_channels=in_channels, kernel_size=1, stride=1)\n",
    "        self.branch2_2 = self.deconv(in_channels=in_channels, out_channels=in_channels, kernel_size=3, stride=1)\n",
    "        self.branch2_3 = self.deconv(in_channels=in_channels, out_channels=out_channels, kernel_size=2, stride=2)\n",
    "        \n",
    "        self.branch3_1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.branch3_2 = self.deconv(in_channels=in_channels, out_channels=out_channels, kernel_size=1, stride=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        branch1 = self.branch1_1(x)\n",
    "        \n",
    "        print(branch1.shape)\n",
    "        \n",
    "        branch2 = self.branch2_1(x)\n",
    "        branch2 = self.branch2_2(branch2)\n",
    "        branch2 = self.branch2_3(branch2)\n",
    "        \n",
    "        print(branch2.shape)\n",
    "        \n",
    "        branch3 = self.branch3_1(x)\n",
    "        branch3 = self.branch3_2(branch3)\n",
    "        \n",
    "        print(branch3.shape)\n",
    "        \n",
    "        outputs = [branch1, branch2, branch3]\n",
    "        \n",
    "        return torch.cat(outputs, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ff5484f2-37a8-43d1-b3f3-73282fab2813",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = torch.from_numpy(np.random.uniform(low=0.0, high=10.0, size=(3, 128, 128))).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "05392821-e4f8-42b6-979a-21d87b82dc35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dec = DecoderBlock(in_channels=3, out_channels=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "316e5beb-aa6b-4aa1-b8a3-74804bcc66e0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 260, 260])\n",
      "torch.Size([1, 64, 64])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 1. Expected size 256 but got size 260 for tensor number 1 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dec(x)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[39], line 33\u001b[0m, in \u001b[0;36mDecoderBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(branch3\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     31\u001b[0m outputs \u001b[38;5;241m=\u001b[39m [branch1, branch2, branch3]\n\u001b[0;32m---> 33\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(outputs, \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 1. Expected size 256 but got size 260 for tensor number 1 in the list."
     ]
    }
   ],
   "source": [
    "dec(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097b3274-40d0-4244-b940-0ebce9dcd367",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
